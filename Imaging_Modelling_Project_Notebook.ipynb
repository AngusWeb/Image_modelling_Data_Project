{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "481e8201-515e-4fa8-88b7-c0cc141b3e08",
   "metadata": {},
   "source": [
    "# Custom YOLO Model\n",
    "\n",
    "I used the YOLOv8 nano model and retrained it to help my program identify the correct links on a webpage to click.\n",
    "\n",
    "## Model Training\n",
    "This code snippet shows the process I used to create the custom model, along with the annotated screenshots I prepared using 'labelImg'.\n",
    "\n",
    "## Model Evaluation\n",
    "I evaluated the current model and found it to have an impressive 97.7% accuracy. This high accuracy can be attributed to the model's power and the relative simplicity of the task.\n",
    "\n",
    "## Testing\n",
    "Before integrating the custom model into my main program, I thoroughly tested it to ensure its performance and reliability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736994f3-475d-421f-855c-2c881268b38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")  # load a pretrained model\n",
    "# Train the model\n",
    "model.train(data='dataset.yaml', epochs=100, imgsz=640)\n",
    "\n",
    "metrics = model.val() #eval\n",
    "# Load an image\n",
    "image = cv2.imread('test.png')\n",
    "# Perform link detection\n",
    "results = model(image)\n",
    "# Visualise the results\n",
    "annotated_image = results[0].plot()\n",
    "cv2.imshow('Link Detection', annotated_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "def testing():\n",
    "    model = YOLO('./runs/detect/train16/weights/best.pt')\n",
    "    image = cv2.imread('test.png')\n",
    "    results = model(image)\n",
    "    \n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "            cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow('Detections', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faf4dbac-8724-4ec1-8fcb-948a0cc2fcac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyautogui\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyautogui\n",
    "import time\n",
    "import keyboard\n",
    "import pytesseract\n",
    "from PIL import  ImageGrab\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import requests\n",
    "from ultralytics import YOLO\n",
    "import easyocr\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e3a455-c568-4a50-b0aa-332746c14ad9",
   "metadata": {},
   "source": [
    "# Project Setup\n",
    "\n",
    "I begin by initialising various variables and the two models I'll be using for this data analytics project.\n",
    "\n",
    "## Current Date\n",
    "I retrieve the current day to add dates to my data later in the project.\n",
    "\n",
    "## OCR Screen Cropping\n",
    "I set `left`, `top`, and other values to specify which section of the screen to crop for OCR in the second section.\n",
    "\n",
    "## OCR Model\n",
    "For optical character recognition, I use the pre-trained EasyOCR English model.\n",
    "\n",
    "## Link Detection Model\n",
    "For link detection, I employ a custom-trained YOLOv8 model, specifically the lightweight nano version (before training).\n",
    "\n",
    "## Data Mapping\n",
    "I define a mapping dictionary and a rolls list for data mapping once I've gathered the necessary information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25dd3864-8c77-4dc2-a9d1-9fb15fc76c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting now!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting now!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m current_day \n\u001b[1;32m----> 3\u001b[0m current_day  \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mday\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\u001b[39;00m\n\u001b[0;32m      6\u001b[0m left \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m846\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Starting now!\")\n",
    "global current_day \n",
    "current_day  = datetime.datetime.now().day\n",
    "#pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "\n",
    "left = 846\n",
    "top = 506\n",
    "right = 1073\n",
    "bottom = 666\n",
    "messages_already_send = []\n",
    "\n",
    "# Initialise the YOLOY v8 custom model\n",
    "model = YOLO('./best_link_model/best.pt')\n",
    "\n",
    "# Initialise the EasyOCR reader\n",
    "reader = easyocr.Reader(['en'], gpu = True)  # Specify the language(s) you want to recognize\n",
    "\n",
    "stat_mapping = {\n",
    "        'melee damage': 'md',        'multishot': 'ms',        'fire rate': 'fr',        'attack speed': 'as',        'damage to corpus': 'corp',\n",
    "        'damage to grineer': 'grin',        'damage to infested': 'inf',        'mpact': 'imp',        'puncture': 'pun',        'slash': 'slash',\n",
    "        'cold': 'cold',        'electric': 'ele',        'heat': 'heat',        'toxin': 'tox',        'combo duration': 'combo',\n",
    "        'critical chance': 'cc',        'critical damage': 'cd',        'slide crit': 'slide',        'finisher damage': 'fin',\n",
    "        'projectile speed': 'pfs',        'ammo': 'ammo',        'magazine': 'mag',        'punch through': 'pt',        'reload speed': 'reload',\n",
    "        'range': 'rng',        'status chance': 'sc',        'status duration': 'sd',        'weapon recoil': 'rec',        'zoom': 'z',\n",
    "        'initial combo': 'ic',        'heavy attack': 'eff',        'combo chance': 'combogain'\n",
    "    }\n",
    "\n",
    "# this is a reference list for the in game items I want the program to flag\n",
    "perfect_rolls = [    ['ic', 'cc', 'cd'],    ['cc', 'cd', 'md'],    ['cc', 'cd', 'ms'],    ['cc', 'cd', 'as'],    ['cd', 'rng', 'as']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534662fa-d5fb-4284-ac11-81d11600a6b0",
   "metadata": {},
   "source": [
    "# OCR Data Processing\n",
    "\n",
    "This function processes the main screenshot after applying EasyOCR and uses logic to add the extracted data to my DataFrame if it meets certain criteria.\n",
    "\n",
    "## Data Mapping\n",
    "I leverage the consistent order of data and specific string key characters (such as '+' and `isdigit()`) to assign the OCR list of strings to the correct column in my DataFrame.\n",
    "\n",
    "## Data Filtering\n",
    "To avoid massive, unreadable DataFrames and CSVs, I filter out all the less important rows, focusing on the essential information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09c58992-30cb-4f06-a143-9aeb57dafe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(df, input_list,username_value,time_value,tradetext_value):\n",
    "    full = False\n",
    "    #close function when false positive happens (1/50 of the time)\n",
    "    if len(input_list) < 3:\n",
    "        return(df)\n",
    "        \n",
    "    if len(input_list[0].split()) == 3:\n",
    "        weapon = ' '.join(input_list[0].split()[:2])\n",
    "    else:\n",
    "        try:\n",
    "            weapon = input_list[0].split()[0]\n",
    "        except IndexError:\n",
    "            weapon = 'index error'  \n",
    "\n",
    "    # Extract name\n",
    "    if not input_list[1].startswith('+'):\n",
    "        name = input_list[0].split(weapon)[-1].strip() + ' ' + input_list[1]\n",
    "    else:\n",
    "        name = input_list[0].split(weapon)[-1].strip()\n",
    "\n",
    "    # Initialise stat variables\n",
    "    stat_1, stat_1_value, stat_2, stat_2_value, stat_3, stat_3_value, stat_4, stat_4_value = '', '', '', '', '', '', '', ''\n",
    "\n",
    "    # Extract stat information\n",
    "    for i, item in enumerate(input_list):\n",
    "        if '(x2' not in item:           \n",
    "            if any(char.isdigit() for char in item):\n",
    "                if not stat_1:\n",
    "                        stat_1 = ' '.join(item.split()[1:]).lower()\n",
    "                        if not stat_1:\n",
    "                            try:\n",
    "                                stat_1 = input_list[i+1]\n",
    "                            except:\n",
    "                                stat_1 = None\n",
    "                        stat_1_value = item.split()[0]\n",
    "                elif not stat_2:\n",
    "\n",
    "                        stat_2 = ' '.join(item.split()[1:]).lower()\n",
    "                        if not stat_2:\n",
    "                            try:\n",
    "                                stat_2 = input_list[i+1]\n",
    "                            except:\n",
    "                                stat_2 = None\n",
    "                        stat_2_value = item.split()[0]\n",
    "                elif not stat_3:\n",
    "\n",
    "                        stat_3 = ' '.join(item.split()[1:]).lower()\n",
    "                        if not stat_3:\n",
    "                            try:\n",
    "                                stat_3 = input_list[i+1]\n",
    "                            except:\n",
    "                                stat_3 = None\n",
    "                        stat_3_value = item.split()[0]\n",
    "                elif not stat_4 and any(char.isdigit() for char in item):\n",
    "                    full = True\n",
    "                    stat_4_parts = item.split()\n",
    "                    stat_4_value = stat_4_parts[0]\n",
    "                    if stat_4_parts[1:]:\n",
    "                        stat_4 = ' '.join(stat_4_parts[1:])\n",
    "                    else:\n",
    "                        stat_4 = input_list[i+1]\n",
    "    if full == False:\n",
    "        return(df)\n",
    "    # Create a new row as a dictionary\n",
    "    new_row = {\n",
    "        'weapon': weapon,        'name': name,        'username':username_value,        'time':time_value,        'full': full,        'stat_1': stat_1,\n",
    "        'stat_1_value': stat_1_value,        'stat_2': stat_2,        'stat_2_value': stat_2_value,        'stat_3': stat_3,\n",
    "        'stat_3_value': stat_3_value,        'stat_4': stat_4,        'stat_4_value': stat_4_value,        'tradetext':tradetext_value\n",
    "    }\n",
    "    # Map stat values to aliases\n",
    "    roll_parts = []\n",
    "    for i in range(1, 5):\n",
    "        stat_key = f'stat_{i}'\n",
    "        if new_row[stat_key].strip():\n",
    "            stat_alias = ''\n",
    "            for stat, alias in stat_mapping.items():\n",
    "                if stat in new_row[stat_key].strip().lower():\n",
    "                    stat_alias = alias\n",
    "                    break\n",
    "            if i == 4:\n",
    "                stat_alias = '-' + stat_alias\n",
    "            roll_parts.append(stat_alias)\n",
    "\n",
    "    new_row['roll'] = ','.join(roll_parts)\n",
    "\n",
    "    new_row['perfect'] = False\n",
    "    if any(set(new_row['roll'].split(',')[:3]) == set(perfect_roll) for perfect_roll in perfect_rolls):\n",
    "        new_row['perfect'] = True\n",
    "    # Convert the row data to a DataFrame\n",
    "    new_row = pd.DataFrame([new_row])\n",
    "\n",
    "    # Concatenate the new row with the existing DataFrame\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1224cb-d89f-45f3-aa46-aed7eba9499a",
   "metadata": {},
   "source": [
    "# Screenshot Processing\n",
    "\n",
    "This function captures a screenshot of the screen, crops it to the desired region, and then converts the cropped image into a NumPy array. I use this format because it is the input format required by EasyOCR for further processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "359f4dd6-9e42-43e0-b0e5-1ecc85b8cb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_image_easyocr(left, top, right, bottom):\n",
    "    # Capture the specified region of the screen\n",
    "    screenshot = ImageGrab.grab(bbox=(left, top, right, bottom))\n",
    "    screenshot = screenshot.convert('RGB')\n",
    "    # Convert the PIL image to a numpy array\n",
    "    screenshot_np = np.array(screenshot)\n",
    "    \n",
    "    return screenshot_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e44b18-194d-4983-a8c1-5ee01bddcb4e",
   "metadata": {},
   "source": [
    "# OCR Processing\n",
    "\n",
    "This function performs optical character recognition (OCR) on the NumPy array, converting it into a list of strings.\n",
    "\n",
    "## Optimisation\n",
    "I split up the screenshot capture and OCR processes to optimise my program further. By doing this, I can perform OCR when my program needs to sleep anyway due to webpage loading, making efficient use of the available time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a107e94-2259-42e9-81cc-f4365f33fd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def easyocr_process(screenshot_np):\n",
    "    results = reader.readtext(screenshot_np, detail = 0)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c27cb8a-988c-46a7-a8c5-72878cf9b19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_name_and_time(line_top, line_bottom):\n",
    "    \n",
    "    name_value = None\n",
    "    time_value = None\n",
    "    for i in range(2):\n",
    "        line_left = 515\n",
    "        line_right = 860\n",
    "\n",
    "        line_image = ocr_image_easyocr(line_left, line_top, line_right, line_bottom)\n",
    "        line_text = easyocr_process(line_image)\n",
    "        if i > 0:\n",
    "            print(f\"moved upwards new trade text: {line_text}\")\n",
    "        if len(line_text) > 0:\n",
    "            \n",
    "            line_text = line_text[0]\n",
    "        if '.' in line_text:\n",
    "            # Extract the time and name values from the line text\n",
    "            time_start = line_text.find('[') + 1\n",
    "            time_end = line_text.find(']')\n",
    "            time_value = line_text[time_start:time_end]\n",
    "\n",
    "            name_start = time_end + 2\n",
    "            name_value = line_text[name_start:].split(':')[0].strip()\n",
    "            time_value = f\"{current_day} {time_value}\"\n",
    "            break\n",
    "        else:\n",
    "            line_top -= 32\n",
    "            line_bottom-= 32\n",
    "            print(f\"Couldnt find '.': {line_text}\")\n",
    "            \n",
    "    if name_value is None:\n",
    "        print(f\"No name found on the line with the link: {line_text}\")\n",
    "    return name_value, time_value,line_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf60d6fb-f3de-4723-865f-a7338bd16c60",
   "metadata": {},
   "source": [
    "# Main Function\n",
    "\n",
    "This is my main function that runs the entire program. Its primary responsibility is handling the YOLO model, which is used to identify links on the page within a specific area and then loop through those links.\n",
    "\n",
    "## Link Selection and OCR\n",
    "Each time a link is selected, the function calls other functions to perform OCR on the visible page as well as the page that appears when the link is clicked.\n",
    "\n",
    "## PyAutoGUI\n",
    "I use PyAutoGUI to control the mouse and keyboard for automation. I opted for non-standard functions as I found them to be more reliable when some automated clicks are suppressed.\n",
    "\n",
    "## Operation Ordering\n",
    "The order of operations might seem slightly odd, but it's designed to perform process-intensive tasks like EasyOCR and YOLO models when the program needs to wait for the page to load anyway.\n",
    "\n",
    "## Time Values and Screenshot Processing\n",
    "The presence of `current` and `regular` time values, as well as the last screenshot processing, is a result of this ordering.\n",
    "\n",
    "## Link Coordinates\n",
    "The y-coordinates of the links are used for OCR selection on the first page.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83fe85c-e779-4cd9-892c-9757e5385aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_links(df,model):\n",
    "    # Set the region of interest (ROI) coordinates\n",
    "    roi_left = 515\n",
    "    roi_top = 173\n",
    "    roi_right = 1822\n",
    "    roi_bottom = 953\n",
    "    screenshot_np = None  \n",
    "\n",
    "    while True:\n",
    "        screenshot = pyautogui.screenshot(region=(roi_left, roi_top, roi_right - roi_left, roi_bottom - roi_top))\n",
    "        screenshot = cv2.cvtColor(np.array(screenshot), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Perform link detection using the YOLOv8 model\n",
    "        results = model(screenshot)\n",
    "\n",
    "        # Iterate over the detected links\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            for box in boxes:\n",
    "                # Extract the link position from the bounding box\n",
    "                x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "                link_center = (int((x1 + x2) / 2) + roi_left, int((y1 + y2) / 2) + roi_top)\n",
    "                link_y = link_center[1]\n",
    "                #area of the page when to bound box of the link is found\n",
    "                line_top = link_y - 16\n",
    "                line_bottom = link_y + 16\n",
    "                    \n",
    "                pyautogui.moveTo(link_center[0], link_center[1])\n",
    "                current_name_value, current_time_value,current_line_text = extract_name_and_time(line_top, line_bottom)\n",
    "                time.sleep(0.2)\n",
    "                pyautogui.mouseDown(button='left')\n",
    "                pyautogui.mouseUp(button='left')\n",
    "\n",
    "                time.sleep(0.6)\n",
    "                #last loop image processing\n",
    "                if screenshot_np is not None:\n",
    "                    input_list = easyocr_process(screenshot_np)\n",
    "                    df = format_input(df, input_list,name_value,time_value,line_text)\n",
    "                else:\n",
    "                    time.sleep(0.3)\n",
    " \n",
    "                time_value = current_name_value\n",
    "                name_value = current_name_value\n",
    "                line_text = current_line_text\n",
    "\n",
    "                screenshot_np = ocr_image_easyocr(left, top, right, bottom)\n",
    "\n",
    "                # Press the escape key if the screen has changed significantly\n",
    "                keyboard.send('esc')\n",
    "                \n",
    "                time.sleep(0.2)\n",
    "                keyboard.send('t')\n",
    "                time.sleep(0.2)\n",
    "        #processing last screenshot before breaking\n",
    "        input_list = easyocr_process(screenshot_np)\n",
    "        df = format_input(df, input_list,name_value,time_value,line_text)\n",
    "        # Break the loop if all links have been clicked\n",
    "        break\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8215006-77c4-49ef-8c70-1c45904165a8",
   "metadata": {},
   "source": [
    "This functuon uses webhooks this sends a discord message when a link is flagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7e111a-d286-4fcd-8b6c-649c1dbe40f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_discord_message(message):\n",
    "    payload = {\n",
    "        \"content\": message\n",
    "    }\n",
    "    response = requests.post('xxxxxxxxxxxxx', json=payload)\n",
    "    if response.status_code == 204:\n",
    "        print(message)\n",
    "        \n",
    "    else:\n",
    "        print(f\"Failed to send message. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efef6bb-6612-4b7b-9260-40d49ce2357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up dataframe\n",
    "df = pd.DataFrame(columns=['weapon','name','username','perfect','roll', 'full', 'stat_1', 'stat_1_value', 'stat_2', 'stat_2_value',\n",
    "                           'stat_3', 'stat_3_value', 'stat_4', 'stat_4_value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cde83ba-5dc7-42c8-92db-4099d931c45c",
   "metadata": {},
   "source": [
    "# Main Code\n",
    "\n",
    "The main code continuously loops over new data, identifying key links and sending Discord messages containing their DataFrame information.\n",
    "\n",
    "## Data Persistence\n",
    "It saves a CSV file of important links as well as all links encountered during the process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f64246-e75f-42c9-9b2d-38a058ccd26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    time.sleep(0.2)\n",
    "    pyautogui.scroll(-5000) \n",
    "    time.sleep(0.2)\n",
    "    pyautogui.scroll(400)\n",
    "    df = click_links(df,model)\n",
    "\n",
    "    df = df.drop_duplicates(subset=['weapon', 'stat_1_value'], keep='first')\n",
    "    columnstodrop = ['tradetext','full']\n",
    "    \n",
    "    df['id'] = df['stat_1_value'].astype(str) + df['stat_2_value'].astype(str) + df['stat_3_value'].astype(str) + df['stat_4_value'].astype(str)\n",
    "    \n",
    "    dfshort = df[df['perfect']==True]\n",
    "    dfshort = dfshort[['weapon','roll','username','time','id']]\n",
    "    print(dfshort.to_string(index=False))\n",
    "    #checking for important rows and sending discord message\n",
    "    for index, row in df.iterrows():\n",
    "        if row['perfect'] == True:\n",
    "            message = f\"Weapon: {row['weapon']}\\nRoll: {row['roll']}\\nUsername:{row['username']}\"\n",
    "            rivenid = row['weapon'] + str(row['stat_1_value'])\n",
    "            username = row['username']\n",
    "            if rivenid not in messages_already_send and username not in messages_already_send:\n",
    "                send_discord_message(message)\n",
    "                messages_already_send.append(rivenid)\n",
    "                messages_already_send.append(username)\n",
    "                \n",
    "    dfshort.to_csv('short-trade.csv', mode='a', na_rep='N/A', header=False, index=False, escapechar=\"\\n\")\n",
    "    df.to_csv('trade.csv', mode='a', na_rep='N/A', header=False, index=False, escapechar=\"\\n\")\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b480d9b-928c-49f8-ace9-68f7793f9249",
   "metadata": {},
   "source": [
    "This is a function I used for identifing screen coordinates from screenshots using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8992e5a-c6c3-4bdd-9557-cbd8b974bf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "screenshot = cv2.imread('test.png')\n",
    "\n",
    "def mouse_callback(event):\n",
    "    if event.button == 1:  # Left mouse button\n",
    "        x, y = event.xdata, event.ydata\n",
    "        print(f\"Clicked coordinates: ({int(x)}, {int(y)})\")\n",
    "\n",
    "plt.imshow(cv2.cvtColor(screenshot, cv2.COLOR_BGR2RGB))\n",
    "plt.connect('button_press_event', mouse_callback)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0491e5e-1153-4154-b023-1440db5076c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
